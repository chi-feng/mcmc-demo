<html>
<head>
<title>The Markov-chain Monte Carlo Interactive Gallery</title>
<style>
body { max-width: 50em; padding: 2em 1em; margin: 0 auto; }
a, a:visited { text-decoration: none; color: #369; }
a:hover { text-decoration: underline; }
table { width: 100%; border-collapse: collapse; }
td img {width: 100%; }
li { margin-bottom: 0.5em; }
.references p { padding-left: 1.4em ; text-indent: -1.4em ; }
</style>
</head>
<body>
<h2>The Markov-chain Monte Carlo Interactive Gallery</h2>
<p>Click on an algorithm below to view interactive demo:</p>
<ul>
    <li><a href="app.html?algorithm=RandomWalkMH&target=banana">Random Walk Metropolis Hastings</a></li>
    <li><a href="app.html?algorithm=AdaptiveMH&target=banana">Adaptive Metropolis Hastings</a> <a href="#ref-1" class="reference">[1]</a></li>
    <li><a href="app.html?algorithm=HamiltonianMC&target=banana">Hamiltonian Monte Carlo</a> <a href="#ref-2" class="reference">[2]</a></li>
    <li><a href="app.html?algorithm=NaiveNUTS&target=banana">No-U-Turn Sampler</a> <a href="#ref-2" class="reference">[2]</a></li>
    <li><a href="app.html?algorithm=MALA&target=banana">Metropolis-adjusted Langevin Algorithm (MALA)</a> <a href="#ref-3" class="reference">[3]</a></li>
    <li><a href="app.html?algorithm=H2MC&target=banana">Hessian-Hamiltonian Monte Carlo (H2MC)</a> <a href="#ref-4" class="reference">[4]</a></li>
    <li><a href="app.html?algorithm=GibbsSampling&target=banana">Gibbs Sampling</a></li>
    <li><a href="app.html?algorithm=SVGD&target=banana&delay=0">Stein Variational Gradient Descent (SVGD)</a> <a href="#ref-5" class="reference">[5]</a></li>
    <li><a href="app.html?algorithm=RadFriends-NS&target=banana">Nested Sampling with RadFriends (RadFriends-NS)</a> <a href="#ref-6" class="reference">[6]</a></li>
    <li><a href="app.html?algorithm=DE-MCMC-Z&target=banana">Differential Evolution Metropolis (Z)</a> <a href="#ref-7" class="reference">[7]</a></li>
    <li><a href="app.html?algorithm=MicrocanonicalHamiltonianMC&target=banana">Microcanonical Hamiltonian Monte Carlo</a> <a href="#ref-8" class="reference">[8]</a></li>
</ul>
<p>View the source code on github: <a href="https://github.com/chi-feng/mcmc-demo">https://github.com/chi-feng/mcmc-demo</a>.</p>
<h3>References</h3>
<div class="references">
<p id="ref-1">[1] H. Haario, E. Saksman, and J. Tamminen, <a target="_blank" href="http://projecteuclid.org/euclid.bj/1080222083">An adaptive Metropolis algorithm</a> (2001)</p>
<p id="ref-2">[2] M. D. Hoffman, A. Gelman, <a target="_blank" href="http://arxiv.org/abs/1111.4246">The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo</a> (2011)</p>
<p id="ref-3">[3] G. O. Roberts, R. L. Tweedie, <a target="_blank" href="http://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/Langevin/RobertsTweedieBernoulli1996.pdf">Exponential Convergence of Langevin Distributions and Their Discrete Approximations</a> (1996)</p>
<p id="ref-4">[4] Li, Tzu-Mao, et al. <a target="_blank" href="https://people.csail.mit.edu/tzumao/h2mc/">Anisotropic Gaussian mutations for metropolis light transport through Hessian-Hamiltonian dynamics</a> ACM Transactions on Graphics 34.6 (2015): 209.</p>
<p id="ref-5">[5] Q. Liu, et al. <a target="_blank" href="http://www.cs.dartmouth.edu/~dartml/project.html?p=vgd">Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm</a> Advances in Neural Information Processing Systems. 2016.</p>
<p id="ref-6">[6] J. Buchner <a target="_blank" href="https://arxiv.org/abs/1407.5459"> A statistical test for Nested Sampling algorithms</a> Statistics and Computing. 2014.</p>
<p id="ref-7">[7] Cajo J. F. ter Braak & Jasper A. Vrugt <a target="_blank" href="https://link.springer.com/article/10.1007/s11222-008-9104-9">Differential Evolution Markov Chain with snooker updater and fewer chains</a> Statistics and Computing. 2008.</p>
<p id="ref-8">[8] Jakob Robnik, G. Bruno De Luca, Eva Silverstein, Uro≈° Seljak <a target="_blank" href="https://arxiv.org/abs/2212.08549">Microcanonical Hamiltonian Monte Carlo</a></p>
</div>
</body>
